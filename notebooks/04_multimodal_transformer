# ==============================================================================
# 1. IMPORTS & CONFIGURATION
# ==============================================================================
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from pathlib import Path
from PIL import Image

from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error
from scipy.stats import wilcoxon

import tensorflow as tf
from tensorflow.keras import layers, models, Input
from tensorflow.keras.callbacks import EarlyStopping
# -------------------------------
# Global Parameters
# -------------------------------
IMG_SIZE = 64
IMG_EMB_DIM = 64

HISTORY_STEPS = 12
FUTURE_STEPS = 6

BATCH_SIZE = 32
EPOCHS = 30
LR = 1e-4

WEATHER_COLS = [
    "AMBIENT_TEMPERATURE",
    "MODULE_TEMPERATURE",
    "IRRADIATION"
]
# ==============================================================================
# 2. PV DATA
# ==============================================================================
pv_df = pd.read_csv("data/2019_pv_raw.csv")
pv_df.columns = ["timestamp", "power"]
pv_df["timestamp"] = pd.to_datetime(pv_df["timestamp"])
pv_df = pv_df.set_index("timestamp").sort_index().dropna()

scaler = StandardScaler()
pv_df["power_scaled"] = scaler.fit_transform(pv_df[["power"]])
# ==============================================================================
# 3. WEATHER DATA
# ==============================================================================
weather_df = pd.read_csv("data/Plant_2_Weather_Sensor_Data.csv")
weather_df["DATE_TIME"] = pd.to_datetime(weather_df["DATE_TIME"])
weather_df = weather_df.set_index("DATE_TIME")[WEATHER_COLS]

weather_df = (
    weather_df
    .resample("1min")
    .mean()
    .interpolate()
    .ffill()
    .bfill()
)
# ==============================================================================
# 4. IMAGE ENCODING
# ==============================================================================
def build_image_encoder():
    inp = Input(shape=(IMG_SIZE, IMG_SIZE, 3))
    x = layers.Conv2D(32, 3, activation="relu")(inp)
    x = layers.MaxPooling2D()(x)
    x = layers.Conv2D(64, 3, activation="relu")(x)
    x = layers.GlobalAveragePooling2D()(x)
    out = layers.Dense(IMG_EMB_DIM, activation="relu")(x)
    return models.Model(inp, out)

image_encoder = build_image_encoder()
def load_and_encode_images(img_dir, limit=20000):
    images, times = [], []
    files = sorted(Path(img_dir).rglob("*.jpg"))[:limit]

    for f in files:
        ts = pd.to_datetime(f.stem, format="%Y%m%d%H%M%S", errors="coerce")
        if pd.isna(ts):
            continue
        img = Image.open(f).resize((IMG_SIZE, IMG_SIZE)).convert("RGB")
        images.append(np.asarray(img) / 255.0)
        times.append(ts)

    emb = image_encoder.predict(np.array(images), batch_size=32, verbose=1)
    return pd.DataFrame(emb, index=pd.to_datetime(times)).sort_index()
# ==============================================================================
# 5. MERGE MODALITIES
# ==============================================================================
img_emb_df = load_and_encode_images("/kaggle/input/pv-forecast-dataset/2019_01_images_raw")

full_df = pd.merge_asof(
    pv_df.sort_index(),
    img_emb_df.sort_index(),
    left_index=True,
    right_index=True,
    tolerance=pd.Timedelta("2min"),
    direction="nearest"
)

full_df = pd.merge_asof(
    full_df.sort_index(),
    weather_df.sort_index(),
    left_index=True,
    right_index=True,
    direction="nearest"
)

full_df = full_df.ffill().bfill().dropna()
assert len(full_df) > 500, "Dataset too small"
# ==============================================================================
# 6. SEQUENCE GENERATION
# ==============================================================================
def build_sequences(df):
    X_p, X_i, X_w, y = [], [], [], []

    power = df["power_scaled"].values
    img_vals = df.iloc[:, 2:2+IMG_EMB_DIM].values
    weather_vals = df[WEATHER_COLS].values

    for i in range(len(df) - HISTORY_STEPS - FUTURE_STEPS):
        X_p.append(power[i:i+HISTORY_STEPS])
        X_i.append(img_vals[i+HISTORY_STEPS])
        X_w.append(weather_vals[i+HISTORY_STEPS])
        y.append(power[i+HISTORY_STEPS:i+HISTORY_STEPS+FUTURE_STEPS])

    return (
        np.array(X_p)[..., None],
        np.array(X_i),
        np.array(X_w),
        np.array(y)
    )
# ==============================================================================
# 7. MULTIMODAL TRANSFORMER MODEL
# ==============================================================================
def transformer_encoder(x, head_size, num_heads, ff_dim, dropout=0.1):
    x_norm = layers.LayerNormalization(epsilon=1e-6)(x)
    attn = layers.MultiHeadAttention(
        key_dim=head_size,
        num_heads=num_heads,
        dropout=dropout
    )(x_norm, x_norm)
    x = x + attn

    x_ff = layers.LayerNormalization(epsilon=1e-6)(x)
    x_ff = layers.Dense(ff_dim, activation="relu")(x_ff)
    return x + x_ff
def build_final_model():
    seq_in = Input(shape=(HISTORY_STEPS, 1 + len(WEATHER_COLS)))
    x = transformer_encoder(seq_in, 64, 4, 64)
    x = layers.GlobalAveragePooling1D()(x)

    img_in = Input(shape=(IMG_EMB_DIM,))
    y = layers.Dense(64, activation="relu")(img_in)

    fusion = layers.Concatenate()([x, y])
    fusion = layers.Dense(128, activation="relu")(fusion)

    out = layers.Dense(FUTURE_STEPS)(fusion)

    model = models.Model([seq_in, img_in], out)
    model.compile(
        optimizer=tf.keras.optimizers.Adam(LR),
        loss="mse"
    )
    return model
# ==============================================================================
# 8. TRAINING & EVALUATION
# ==============================================================================
X_p, X_i, X_w, y = build_sequences(full_df)

split = int(0.8 * len(X_p))
X_p_tr, X_p_te = X_p[:split], X_p[split:]
X_i_tr, X_i_te = X_i[:split], X_i[split:]
X_w_tr, X_w_te = X_w[:split], X_w[split:]
y_tr, y_te = y[:split], y[split:]
D_MODEL = 64
def transformer_encoder(x, d_model, num_heads, ff_dim, dropout=0.1):
    # Self-attention
    attn_out = layers.MultiHeadAttention(
        key_dim=d_model // num_heads,
        num_heads=num_heads,
        dropout=dropout
    )(x, x)

    x = layers.Add()([x, attn_out])
    x = layers.LayerNormalization(epsilon=1e-6)(x)

    # Feed-forward network
    ff_out = layers.Dense(ff_dim, activation="relu")(x)
    ff_out = layers.Dense(d_model)(ff_out)

    x = layers.Add()([x, ff_out])
    return layers.LayerNormalization(epsilon=1e-6)(x)
def build_final_model():
    # -------------------------------
    # Temporal input (Power + Weather)
    # -------------------------------
    seq_in = Input(shape=(HISTORY_STEPS, 1 + len(WEATHER_COLS)))

    # ðŸ”‘ Project to Transformer dimension
    x = layers.Dense(D_MODEL)(seq_in)

    # Transformer block
    x = transformer_encoder(
        x,
        d_model=D_MODEL,
        num_heads=4,
        ff_dim=128
    )

    x = layers.GlobalAveragePooling1D()(x)

    # -------------------------------
    # Image embedding input
    # -------------------------------
    img_in = Input(shape=(IMG_EMB_DIM,))
    img_feat = layers.Dense(D_MODEL, activation="relu")(img_in)

    # -------------------------------
    # Fusion
    # -------------------------------
    fusion = layers.Concatenate()([x, img_feat])
    fusion = layers.Dense(128, activation="relu")(fusion)
    fusion = layers.Dense(64, activation="relu")(fusion)

    out = layers.Dense(FUTURE_STEPS)(fusion)

    model = models.Model([seq_in, img_in], out)
    model.compile(
        optimizer=tf.keras.optimizers.Adam(LR),
        loss="mse"
    )
    return model
def expand_weather(X_p, X_w):
    w_seq = np.repeat(X_w[:, None, :], HISTORY_STEPS, axis=1)
    return np.concatenate([X_p, w_seq], axis=-1)

X_pw_tr = expand_weather(X_p_tr, X_w_tr)
X_pw_te = expand_weather(X_p_te, X_w_te)

model = build_final_model()
model.fit(
    [X_pw_tr, X_i_tr],
    y_tr,
    epochs=EPOCHS,
    batch_size=BATCH_SIZE,
    callbacks=[EarlyStopping(patience=5, restore_best_weights=True)],
    verbose=1
)
# ==============================================================================
# 9. ABLATION & STATISTICAL SIGNIFICANCE
# ==============================================================================
from sklearn.metrics import mean_squared_error

y_pred = model.predict([X_pw_te, X_i_te])

rmse_full = np.sqrt(mean_squared_error(y_te.flatten(), y_pred.flatten()))
print("Final RMSE:", rmse_full)
# Wilcoxon significance vs baseline
baseline = np.repeat(y_te[:, 0:1], FUTURE_STEPS, axis=1)
stat, p_val = wilcoxon(
    np.abs(y_te.flatten() - y_pred.flatten()),
    np.abs(y_te.flatten() - baseline.flatten())
)

print(f"Wilcoxon p-value: {p_val:.5f}")
# ==============================================================================
# FORECAST COMPARISON PLOT
# ==============================================================================

def plot_forecast_comparison(y_true, y_pred, step=0, horizon=200):
    """
    Plots ground truth vs baseline vs Transformer prediction
    for a selected forecast step.
    """
    # Ground truth
    gt = y_true[:horizon, step]

    # Transformer prediction
    tf_pred = y_pred[:horizon, step]

    # Persistence baseline
    baseline = y_true[:horizon, 0]

    plt.figure(figsize=(14, 5))
    plt.plot(gt, label="Ground Truth", linewidth=2)
    plt.plot(baseline, linestyle="--", label="Baseline (Persistence)")
    plt.plot(tf_pred, label="Multimodal Transformer")

    plt.title(f"PV Power Forecast Comparison (t + {step+1})")
    plt.xlabel("Time Steps")
    plt.ylabel("Scaled Power")
    plt.legend()
    plt.grid(alpha=0.3)
    plt.tight_layout()
    plt.show()
plot_forecast_comparison(y_te, y_pred, step=0)
def inverse_scale(arr):
    return scaler.inverse_transform(
        arr.reshape(-1, 1)
    ).reshape(arr.shape)
y_te_kw = inverse_scale(y_te)
y_pred_kw = inverse_scale(y_pred)

plot_forecast_comparison(y_te_kw, y_pred_kw, step=0)
